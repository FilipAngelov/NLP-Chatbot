{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/filip/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#General modules\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Text processing modules\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# ML modules\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Preprocessing functions\n",
    "def text_preprocessing(text, stop_words):\n",
    "    \"\"\"\n",
    "    Performs tokenization and simple preprocessing.\n",
    "    Args : \n",
    "        @param text (String): Text that needs preprocessing\n",
    "        @return: text (String) : Preprocessed text\n",
    "    \"\"\"\n",
    "    bad_symbols = re.compile('[/(){}\\[\\]\\|@,;+_#]')\n",
    "    fine_symbols = re.compile('[^0-9абвгдѓежзѕијклљмнњопрстќуфхцчџш ]')\n",
    "    stopwords_set = stop_words\n",
    "    lat_to_cyr = {'kj' : 'ќ', 'gj' : 'ѓ', 'zh' : 'ж', 'ch' : 'ч', 'sh' : 'ш', 'dj' : 'ѓ',\n",
    "              'a' : 'а', 'b' : 'б', 'c' : 'ц', 'd' : 'д', 'e' : 'е', 'f' : 'ф', 'g' : 'г',\n",
    "              'h' : 'х', 'i' : 'и', 'j' : 'ј', 'k' : 'к', 'l' : 'л', 'm' : 'м', 'n' : 'н', \n",
    "              'o' : 'о', 'p' : 'п', 'q' : 'љ', 'r' : 'р', 's' : 'с', 't' : 'т', 'u' : 'у',\n",
    "              'v' : 'в', 'w' : 'њ', 'x' : 'џ', 'y' : 'ѕ',  'z' : 'з'\n",
    "             }\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    for item, value in lat_to_cyr.items():\n",
    "        text = re.sub(item, value, text)\n",
    "    \n",
    "    text = bad_symbols.sub(' ', text)\n",
    "\n",
    "    text = fine_symbols.sub('', text)\n",
    "    \n",
    "    text = ' '.join([x for x in text.split() if x and x not in stopwords_set])\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "def load_dataset(source):\n",
    "    # Loading the data from the source\n",
    "    data = pd.read_csv(source)\n",
    "\n",
    "    # Spliting into questions, answers and categories\n",
    "    questions = data.iloc[:, 0]\n",
    "    answers = data.iloc[:, 1]\n",
    "    categories = data.iloc[:, 2]\n",
    "    category_codes = data.iloc[:, 3]\n",
    "    \n",
    "    return questions, answers, categories, category_codes\n",
    "\n",
    "\n",
    "# Load the stop words\n",
    "def load_stop_words(source):\n",
    "    file = open(source, 'r')\n",
    "    sw=file.read().split()\n",
    "    file.close()\n",
    "    return sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the database of questions and building the corpus\n",
    "qus, ans, cat, cat_codes = load_dataset('dataset_brainster.csv')\n",
    "sw = load_stop_words('stop_words.txt')\n",
    "\n",
    "corpus = [text_preprocessing(q, sw) for q in qus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Колку{време}трае академијата(за)дигитален марк...\n",
       "1      колку месеци недели е академијата за дигитален...\n",
       "2      Како се одвива наставата на академијата за диг...\n",
       "3                   Дали наставата за маркетинг е online\n",
       "4        Колку часа неделно има на маркетинг академијата\n",
       "                             ...                        \n",
       "518     Дали добивам диплома по завршување на Академија?\n",
       "519           Како да аплицирам на академијата за UX/UI?\n",
       "520    Како ги одбирате студентите на академијата за ...\n",
       "521    Дали може да се приклучам на листа на кандидат...\n",
       "522    Кои се придобивките од посета на Академијата з...\n",
       "Name: questions, Length: 523, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builting the Count-Vectorized features\n",
    "count_vectorizer = CountVectorizer(strip_accents='unicode') #probaj bez max_features\n",
    "count_vectorizer.fit(corpus)\n",
    "corpus_vec = count_vectorizer.transform(corpus)\n",
    "\n",
    "corpus_vec_df = pd.DataFrame(data = corpus_vec.todense(), columns = count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>15</th>\n",
       "      <th>1630</th>\n",
       "      <th>24</th>\n",
       "      <th>автоматско</th>\n",
       "      <th>адс</th>\n",
       "      <th>академии</th>\n",
       "      <th>академиите</th>\n",
       "      <th>академија</th>\n",
       "      <th>академијата</th>\n",
       "      <th>акредитиран</th>\n",
       "      <th>...</th>\n",
       "      <th>чини</th>\n",
       "      <th>школувањето</th>\n",
       "      <th>јава</th>\n",
       "      <th>јазик</th>\n",
       "      <th>јазици</th>\n",
       "      <th>јак</th>\n",
       "      <th>јљуерѕ</th>\n",
       "      <th>ља</th>\n",
       "      <th>њебдривер</th>\n",
       "      <th>њебсите</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 499 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   15  1630  24  автоматско  адс  академии  академиите  академија  \\\n",
       "0   0     0   0           0    0         0           0          0   \n",
       "1   0     0   0           0    0         0           0          0   \n",
       "2   0     0   0           0    0         0           0          0   \n",
       "3   0     0   0           0    0         0           0          0   \n",
       "4   0     0   0           0    0         0           0          0   \n",
       "\n",
       "   академијата  акредитиран  ...  чини  школувањето  јава  јазик  јазици  јак  \\\n",
       "0            1            0  ...     0            0     0      0       0    0   \n",
       "1            1            0  ...     0            0     0      0       0    0   \n",
       "2            1            0  ...     0            0     0      0       0    0   \n",
       "3            0            0  ...     0            0     0      0       0    0   \n",
       "4            1            0  ...     0            0     0      0       0    0   \n",
       "\n",
       "   јљуерѕ  ља  њебдривер  њебсите  \n",
       "0       0   0          0        0  \n",
       "1       0   0          0        0  \n",
       "2       0   0          0        0  \n",
       "3       0   0          0        0  \n",
       "4       0   0          0        0  \n",
       "\n",
       "[5 rows x 499 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the TF-IDF Vectorized Features\n",
    "tfidf_vectorizer = TfidfVectorizer(strip_accents='unicode')\n",
    "tfidf_vectorizer.fit(corpus)\n",
    "corpus_tfidif = tfidf_vectorizer.transform(corpus)\n",
    "\n",
    "corpus_tfidif_df = pd.DataFrame(data = corpus_tfidif.todense(), columns = tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(523, 499)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidif_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Cosine Similarity Functiom\n",
    "def cos_sim(new_input, corpus): \n",
    "    cosine_function = lambda a, b : np.inner(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    distances = []\n",
    "    for question in corpus:\n",
    "        distances.append(cosine_function(new_input.toarray(), question.toarray()))\n",
    "    max_sim = max(max(max(distances)))\n",
    "    max_arg = np.argmax(distances)\n",
    "    return max_arg, max_sim, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Pearson Similarity Function\n",
    "def pearson_sim(new_input, corpus): \n",
    "    distances = []\n",
    "    for question in corpus:\n",
    "        distances.append(np.corrcoef(new_input.todense(), question.todense())[0, 1])\n",
    "    max_sim = max(distances)\n",
    "    max_arg = np.argmax(distances)\n",
    "    return max_arg, max_sim, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Dice Similarity Function\n",
    "def dice_sim(new_input, corpus):\n",
    "    new_input = new_input.toarray().flatten().astype(bool)\n",
    "    distances = []\n",
    "    for question in corpus:\n",
    "        question = question.toarray().flatten().astype(bool)\n",
    "        distances.append(2.0*np.logical_and(new_input, question).sum()/(new_input.sum() + question.sum()))\n",
    "    max_sim = max(distances)\n",
    "    max_arg = np.argmax(distances)\n",
    "    return max_arg, max_sim, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tq = 'се прифаќа ли ваучер од владата'\n",
    "tq = text_preprocessing(tq, sw)\n",
    "tq = count_vectorizer.transform([tq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "0.4999999999999999\n",
      "Најблиску до прашањето: како да аплицирам за ваучер\n",
      "Одговор:  Најпрво избери ја обуката за која сакаш да го искористиш ваучерот, резервирај го твоето место на истата, а нашиот тим ќе ти помогне во целиот процес на апликација за ваучерот. Дополнително може да се информираш на следниот лник https://vauceri.brainster.co/upatstvo/\n"
     ]
    }
   ],
   "source": [
    "# Getting the closest cosine-score and responding\n",
    "max_arg, max_sim, distances = cos_sim(tq, corpus_vec)\n",
    "\n",
    "print(max_arg)\n",
    "\n",
    "print(max_sim)\n",
    "\n",
    "print('Најблиску до прашањето:', qus[max_arg])\n",
    "print('Одговор: ', ans[max_arg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "0.49798792756539395\n",
      "Најблиску до прашањето: како да аплицирам за ваучер\n",
      "Одговор:  Најпрво избери ја обуката за која сакаш да го искористиш ваучерот, резервирај го твоето место на истата, а нашиот тим ќе ти помогне во целиот процес на апликација за ваучерот. Дополнително може да се информираш на следниот лник https://vauceri.brainster.co/upatstvo/\n"
     ]
    }
   ],
   "source": [
    "# Getting the closest pearson-score and responding\n",
    "max_arg, max_sim, distances = pearson_sim(tq, corpus_vec)\n",
    "\n",
    "print(max_arg)\n",
    "\n",
    "print(max_sim)\n",
    "\n",
    "print('Најблиску до прашањето:', qus[max_arg])\n",
    "print('Одговор: ', ans[max_arg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "0.5\n",
      "Најблиску до прашањето: како да аплицирам за ваучер\n",
      "Одговор:  Најпрво избери ја обуката за која сакаш да го искористиш ваучерот, резервирај го твоето место на истата, а нашиот тим ќе ти помогне во целиот процес на апликација за ваучерот. Дополнително може да се информираш на следниот лник https://vauceri.brainster.co/upatstvo/\n"
     ]
    }
   ],
   "source": [
    "# Getting the closest dice-score and responding\n",
    "max_arg, max_sim, distances = dice_sim(tq, corpus_vec)\n",
    "\n",
    "print(max_arg)\n",
    "\n",
    "print(max_sim)\n",
    "\n",
    "print('Најблиску до прашањето:', qus[max_arg])\n",
    "print('Одговор: ', ans[max_arg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tq = 'се прифаќа ли ваучер од владата'\n",
    "tq = text_preprocessing(tq, sw)\n",
    "tq = tfidf_vectorizer.transform([tq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "0.6176566731622903\n",
      "Најблиску до прашањето: како да аплицирам за ваучер\n",
      "Одговор:  Најпрво избери ја обуката за која сакаш да го искористиш ваучерот, резервирај го твоето место на истата, а нашиот тим ќе ти помогне во целиот процес на апликација за ваучерот. Дополнително може да се информираш на следниот лник https://vauceri.brainster.co/upatstvo/\n"
     ]
    }
   ],
   "source": [
    "# Getting the closest cosine-score and responding\n",
    "max_arg, max_sim, distances = cos_sim(tq, corpus_tfidif)\n",
    "\n",
    "print(max_arg)\n",
    "\n",
    "print(max_sim)\n",
    "\n",
    "print('Најблиску до прашањето:', qus[max_arg])\n",
    "print('Одговор: ', ans[max_arg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "0.6161442349675342\n",
      "Најблиску до прашањето: како да аплицирам за ваучер\n",
      "Одговор:  Најпрво избери ја обуката за која сакаш да го искористиш ваучерот, резервирај го твоето место на истата, а нашиот тим ќе ти помогне во целиот процес на апликација за ваучерот. Дополнително може да се информираш на следниот лник https://vauceri.brainster.co/upatstvo/\n"
     ]
    }
   ],
   "source": [
    "# Getting the closest pearson-score and responding\n",
    "max_arg, max_sim, distances = pearson_sim(tq, corpus_tfidif)\n",
    "\n",
    "print(max_arg)\n",
    "\n",
    "print(max_sim)\n",
    "\n",
    "print('Најблиску до прашањето:', qus[max_arg])\n",
    "print('Одговор: ', ans[max_arg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "0.5\n",
      "Најблиску до прашањето: како да аплицирам за ваучер\n",
      "Одговор:  Најпрво избери ја обуката за која сакаш да го искористиш ваучерот, резервирај го твоето место на истата, а нашиот тим ќе ти помогне во целиот процес на апликација за ваучерот. Дополнително може да се информираш на следниот лник https://vauceri.brainster.co/upatstvo/\n"
     ]
    }
   ],
   "source": [
    "# Getting the closest dice-score and responding\n",
    "max_arg, max_sim, distances = dice_sim(tq, corpus_tfidif)\n",
    "\n",
    "print(max_arg)\n",
    "\n",
    "print(max_sim)\n",
    "\n",
    "print('Најблиску до прашањето:', qus[max_arg])\n",
    "print('Одговор: ', ans[max_arg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading modules\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Building the embedding corpus\n",
    "corpus_embedding = [question.split() for question in corpus]\n",
    "\n",
    "corpus_embedding[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36, 42, 1, 12, 11]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_int = Tokenizer(\n",
    "    num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n„“', lower=True,\n",
    "    split=' ', char_level=False, oov_token=None, document_count=0)\n",
    "\n",
    "\n",
    "text_int = word_to_int.fit_on_texts(corpus)\n",
    "\n",
    "text_int = word_to_int.texts_to_sequences(corpus)\n",
    "text_int[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'време трае академијата дигитален маркетинг'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(max(text_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpemb import BPEmb\n",
    "bpemb_mk = BPEmb(lang=\"mk\", dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_corpus = []\n",
    "for question in corpus:\n",
    "    embed_corpus.append(bpemb_mk.embed(question).mean(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.36950657,  0.18893042,  0.01634129, -0.00867986,  0.11965057,\n",
       "       -0.25862342,  0.105135  , -0.13501443, -0.11052115, -0.13546571,\n",
       "        0.14883716, -0.0751087 ,  0.13449328,  0.01924443, -0.17472914,\n",
       "       -0.03395014, -0.06081856, -0.08908772, -0.02118914, -0.27493757,\n",
       "        0.2610376 ,  0.14679416,  0.13678773, -0.042043  , -0.06447043,\n",
       "       -0.03435528, -0.03392672, -0.09542271,  0.00625943,  0.10281787,\n",
       "        0.01958071,  0.03375972, -0.00518758,  0.04028443, -0.21520887,\n",
       "        0.16210842, -0.13096914,  0.03470386,  0.03595701, -0.042074  ,\n",
       "        0.00493985,  0.03202243, -0.12084858, -0.01632114,  0.246698  ,\n",
       "       -0.08829314, -0.03844229, -0.16857372,  0.09927315, -0.19717327,\n",
       "        0.03333686, -0.12733844, -0.04869387,  0.04668472,  0.06395758,\n",
       "       -0.06671644,  0.15618828,  0.25347   ,  0.15353842,  0.09247072,\n",
       "        0.08692227, -0.03039116, -0.36476973,  0.09982427, -0.11355243,\n",
       "        0.08249171, -0.01313242, -0.21146175, -0.00904758, -0.14808556,\n",
       "       -0.29453087, -0.04829215,  0.00328957, -0.013105  ,  0.12570728,\n",
       "        0.12449399,  0.05228   , -0.348326  , -0.064412  ,  0.13901456,\n",
       "        0.11562   ,  0.03501072,  0.26767328,  0.20819142, -0.06911556,\n",
       "        0.14860915, -0.46101278,  0.12119843,  0.3755164 ,  0.09441072,\n",
       "        0.15387486, -0.01541157,  0.05450542,  0.2516926 ,  0.11278886,\n",
       "        0.20355728, -0.28138772, -0.07334299, -0.08932914, -0.08196657,\n",
       "       -0.09707157,  0.204203  , -0.2619327 , -0.171585  , -0.26549745,\n",
       "       -0.13322987,  0.17112659,  0.1000533 , -0.11639415,  0.2228583 ,\n",
       "       -0.04954673,  0.11863727,  0.38089317, -0.00137658, -0.08771785,\n",
       "       -0.06145629, -0.15659158,  0.10310815,  0.015027  ,  0.03059988,\n",
       "       -0.05971685, -0.1282687 , -0.06713872,  0.11374157,  0.04230257,\n",
       "        0.01807843, -0.22198714,  0.345198  , -0.2554333 , -0.06386328,\n",
       "        0.10333272,  0.00374072, -0.09411528, -0.14056514, -0.2342123 ,\n",
       "        0.15809713, -0.07733043,  0.28597912,  0.03231486,  0.01963572,\n",
       "        0.02143758,  0.13121657, -0.01037371, -0.00748629,  0.20116842,\n",
       "        0.02678314,  0.09864329, -0.04315229,  0.03118415,  0.19549358,\n",
       "        0.00154557, -0.08826401,  0.14899257, -0.12375715,  0.04223629,\n",
       "        0.047984  ,  0.05352601,  0.18792728, -0.15870741, -0.10995556,\n",
       "       -0.07973728, -0.26593456,  0.10878043, -0.07550286,  0.1411104 ,\n",
       "        0.04733657,  0.31065458, -0.03564214, -0.17543086,  0.04845371,\n",
       "       -0.09632901,  0.09643929,  0.12056042, -0.244695  ,  0.04197243,\n",
       "        0.01729972, -0.06741358, -0.18921342,  0.06183643,  0.18399729,\n",
       "        0.17864428,  0.03543943,  0.09150057,  0.17411971, -0.01848785,\n",
       "        0.02265529, -0.20309857, -0.03701172, -0.12974158, -0.08126528,\n",
       "        0.02415786,  0.14033057, -0.05761685,  0.14677157, -0.069804  ,\n",
       "        0.04362371, -0.09710128,  0.26600426, -0.07004757, -0.19591726,\n",
       "       -0.22676729,  0.18918729,  0.02769158,  0.108189  , -0.21511658,\n",
       "       -0.09982713, -0.08859957, -0.0238923 , -0.019254  , -0.02799857,\n",
       "        0.00656371, -0.14567757,  0.13910215,  0.00531743, -0.16544686,\n",
       "        0.27980644, -0.38604358,  0.02346128,  0.142673  ,  0.25494286,\n",
       "       -0.08941028,  0.09260815, -0.02476586,  0.06040686,  0.08683543,\n",
       "        0.06859701,  0.23294684, -0.13664214,  0.10796814,  0.03492886,\n",
       "       -0.06144315, -0.08465672, -0.05548558, -0.07726342, -0.18262799,\n",
       "       -0.07687657,  0.019514  , -0.16175659, -0.1434927 ,  0.06133486,\n",
       "       -0.13160685, -0.10243386, -0.14511026,  0.13634743,  0.05876214,\n",
       "        0.29989943, -0.20435543, -0.21928684, -0.13902786,  0.20301886,\n",
       "       -0.2879243 ,  0.02030458,  0.00762157, -0.04890085, -0.04596243,\n",
       "       -0.06068514, -0.05853543,  0.06474086, -0.05010886,  0.21641271,\n",
       "        0.01140386, -0.27018717, -0.01027371, -0.18354757, -0.25843242,\n",
       "        0.01203043,  0.29502058,  0.24212913, -0.17786916, -0.22498071,\n",
       "       -0.16611783, -0.19346057,  0.23518144,  0.20325187, -0.00459871,\n",
       "        0.09695385, -0.09209442,  0.00321845,  0.005362  , -0.01286756,\n",
       "       -0.02719471, -0.20957014,  0.04798142, -0.07999456,  0.04214956,\n",
       "       -0.20886216,  0.17793044,  0.39867982, -0.3604433 , -0.29030675,\n",
       "        0.03428771, -0.20918514,  0.028599  , -0.00762729, -0.15511687,\n",
       "        0.02231371, -0.03119286,  0.09094585,  0.21154486,  0.25300974],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_corpus[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# НАДОЛУ Е ТЕСТ КОД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qus[0])\n",
    "print()\n",
    "print(corpus[112:114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(corpus_vec[112].toarray() * corpus_vec[113].toarray()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inner(corpus_vec[113].toarray()[0], corpus_vec[113].toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import dice, cosine, correlation\n",
    "\n",
    "print('cosine = ', cosine(tq.toarray(), corpus_vec[89].toarray()))\n",
    "\n",
    "print('correlation = ', correlation(tq.toarray(), corpus_vec[89].toarray()))\n",
    "\n",
    "print('dice = ', dice(tq.toarray(), corpus_vec[89].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_function = lambda a, b : np.inner(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "max(max(cosine_function(tq.toarray(), corpus_vec[89].toarray())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inner(tq.toarray(), corpus_vec[89].toarray())[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tq\n",
    "b = corpus_vec[89]\n",
    "print(a)\n",
    "print()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = a==b\n",
    "a = tq\n",
    "b = corpus_vec[89]\n",
    "def dice_sim(a, b):\n",
    "    a = a.toarray().flatten().astype(bool)\n",
    "    b = b.toarray().flatten().astype(bool)\n",
    "    return 2.0*np.logical_and(a, b).sum()/(a.sum() + b.sum())\n",
    "\n",
    "dice_sim(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice(a.toarray(), b.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice([0, 1, 0], [0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_sim(np.asarray([0, 1, 0]), np.asarray([1, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([0, 1, 0])\n",
    "q = np.array([0, 1, 0])\n",
    "\n",
    "print('cosine = ', cosine(p, q))\n",
    "\n",
    "print('correlation = ', correlation(p, q))\n",
    "\n",
    "print('dice = ', dice(p, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_sim_2(a, b):\n",
    "    a = a.astype(bool)\n",
    "    b = b.astype(bool)\n",
    "    return 2.0*np.logical_and(a, b).sum()/(a.sum() + b.sum())\n",
    "\n",
    "dice_sim_2(p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasattr(a, ('toarray', 'flatten'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
